{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"jonnygaese@gmail.com\"\n",
        "!git config --global user.name \"JohnnyG502\""
      ],
      "metadata": {
        "id": "_UkmnhYjFXsx"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XoOotFoMT0S9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colorama"
      ],
      "metadata": {
        "id": "y0BCN_hlBzuh",
        "outputId": "b8050c38-cfe4-4327-f440-7516b20ccb3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (0.4.4)\n",
            "Collecting jsonmerge\n",
            "  Downloading jsonmerge-1.8.0.tar.gz (26 kB)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from jsonmerge) (2.6.0)\n",
            "Building wheels for collected packages: jsonmerge\n",
            "  Building wheel for jsonmerge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonmerge: filename=jsonmerge-1.8.0-py3-none-any.whl size=18013 sha256=e6a0d8f2b1950a363eb76c785a495cbc898b11628a4d272577425ee2db27186e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2f/c8/79/83ddc70e0b20f2df3bbac658c2c5d665b76cedd02e67bd61dc\n",
            "Successfully built jsonmerge\n",
            "Installing collected packages: jsonmerge\n",
            "Successfully installed jsonmerge-1.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/JohnnyG502/pommermanAI.git"
      ],
      "metadata": {
        "id": "hg0Y93n1Faxv",
        "outputId": "f92d62f1-3368-471f-d291-9e68a4aa26d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pommermanAI'...\n",
            "remote: Enumerating objects: 319, done.\u001b[K\n",
            "remote: Counting objects: 100% (319/319), done.\u001b[K\n",
            "remote: Compressing objects: 100% (252/252), done.\u001b[K\n",
            "remote: Total 319 (delta 88), reused 237 (delta 47), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (319/319), 4.30 MiB | 4.79 MiB/s, done.\n",
            "Resolving deltas: 100% (88/88), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd pommermanAI/reinforcement_learning/johannes"
      ],
      "metadata": {
        "id": "xy1CHIukFfgY",
        "outputId": "39c32208-b11b-4aaa-c2ff-6311a4e63295",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/pommermanAI/reinforcement_learning/johannes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull origin main"
      ],
      "metadata": {
        "id": "FnuvZ2IpFhvj",
        "outputId": "f712afdf-0e83-4477-aea9-49870ef4ba76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "From https://github.com/JohnnyG502/pommermanAI\n",
            " * branch            main       -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.insert(0,'/content/reinforcement_learning/johannes/model_action_prun_colab')\n"
      ],
      "metadata": {
        "id": "14bTPofhHzgr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MultiAgentLearning/playground.git\n",
        "%cd playground"
      ],
      "metadata": {
        "id": "VfVhuaeHBmh9",
        "outputId": "5f6384ca-c187-4854-ac08-bea5850a05df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'playground'...\n",
            "remote: Enumerating objects: 2237, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 2237 (delta 8), reused 0 (delta 0), pack-reused 2222\u001b[K\n",
            "Receiving objects: 100% (2237/2237), 2.91 MiB | 11.29 MiB/s, done.\n",
            "Resolving deltas: 100% (1241/1241), done.\n",
            "/content/pommermanAI/reinforcement_learning/johannes/playground/playground\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-4a474be2fc3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'git clone https://github.com/MultiAgentLearning/playground.git'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd playground'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ls' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "C7_Q-6zhDJV2",
        "outputId": "3d611939-c027-46be-e311-4abcea13543d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docker~=3.1\n",
            "  Downloading docker-3.7.3-py2.py3-none-any.whl (134 kB)\n",
            "\u001b[K     |████████████████████████████████| 134 kB 8.4 MB/s \n",
            "\u001b[?25hCollecting gym~=0.10.5\n",
            "  Downloading gym-0.10.11.tar.gz (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 78.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy~=1.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.4.1)\n",
            "Collecting Pillow~=5.0\n",
            "  Downloading Pillow-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 45.7 MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml~=0.15\n",
            "  Downloading ruamel.yaml-0.17.20-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 84.5 MB/s \n",
            "\u001b[?25hCollecting Flask~=0.12\n",
            "  Downloading Flask-0.12.5-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 12.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests~=2.18 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (2.23.0)\n",
            "Collecting jsonmerge~=1.5.1\n",
            "  Downloading jsonmerge-1.5.2.tar.gz (20 kB)\n",
            "Collecting astroid>=2\n",
            "  Downloading astroid-2.9.1-py3-none-any.whl (254 kB)\n",
            "\u001b[K     |████████████████████████████████| 254 kB 78.9 MB/s \n",
            "\u001b[?25hCollecting isort~=4.3.4\n",
            "  Downloading isort-4.3.21-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.2 MB/s \n",
            "\u001b[?25hCollecting pylint>=2\n",
            "  Downloading pylint-2.12.2-py3-none-any.whl (414 kB)\n",
            "\u001b[K     |████████████████████████████████| 414 kB 64.4 MB/s \n",
            "\u001b[?25hCollecting websockets~=6.0\n",
            "  Downloading websockets-6.0-cp37-cp37m-manylinux1_x86_64.whl (88 kB)\n",
            "\u001b[K     |████████████████████████████████| 88 kB 8.8 MB/s \n",
            "\u001b[?25hCollecting websocket-client~=0.53.0\n",
            "  Downloading websocket_client-0.53.0-py2.py3-none-any.whl (198 kB)\n",
            "\u001b[K     |████████████████████████████████| 198 kB 90.8 MB/s \n",
            "\u001b[?25hCollecting python-cli-ui~=0.7.1\n",
            "  Downloading python_cli_ui-0.7.5-py3-none-any.whl (11 kB)\n",
            "Collecting python-rapidjson~=0.6.3\n",
            "  Downloading python_rapidjson-0.6.3-cp37-cp37m-manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 70.0 MB/s \n",
            "\u001b[?25hCollecting Click==7.0\n",
            "  Downloading Click-7.0-py2.py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 10.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from docker~=3.1->-r requirements.txt (line 1)) (1.15.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym~=0.10.5->-r requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym~=0.10.5->-r requirements.txt (line 2)) (1.5.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.6\n",
            "  Downloading ruamel.yaml.clib-0.2.6-cp37-cp37m-manylinux1_x86_64.whl (546 kB)\n",
            "\u001b[K     |████████████████████████████████| 546 kB 61.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=0.21 in /usr/local/lib/python3.7/dist-packages (from Flask~=0.12->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: Jinja2>=2.4 in /usr/local/lib/python3.7/dist-packages (from Flask~=0.12->-r requirements.txt (line 6)) (2.11.3)\n",
            "Collecting Werkzeug<1.0,>=0.7\n",
            "  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\n",
            "\u001b[K     |████████████████████████████████| 327 kB 78.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests~=2.18->-r requirements.txt (line 7)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests~=2.18->-r requirements.txt (line 7)) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests~=2.18->-r requirements.txt (line 7)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests~=2.18->-r requirements.txt (line 7)) (2.10)\n",
            "Requirement already satisfied: jsonschema<3.0.0 in /usr/local/lib/python3.7/dist-packages (from jsonmerge~=1.5.1->-r requirements.txt (line 8)) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.10 in /usr/local/lib/python3.7/dist-packages (from astroid>=2->-r requirements.txt (line 9)) (3.10.0.2)\n",
            "Collecting typed-ast<2.0,>=1.4.0\n",
            "  Downloading typed_ast-1.5.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 57.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools>=20.0 in /usr/local/lib/python3.7/dist-packages (from astroid>=2->-r requirements.txt (line 9)) (57.4.0)\n",
            "Collecting lazy-object-proxy>=1.4.0\n",
            "  Downloading lazy_object_proxy-1.7.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt<1.14,>=1.11 in /usr/local/lib/python3.7/dist-packages (from astroid>=2->-r requirements.txt (line 9)) (1.13.3)\n",
            "Collecting mccabe<0.7,>=0.6\n",
            "  Downloading mccabe-0.6.1-py2.py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: toml>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from pylint>=2->-r requirements.txt (line 11)) (0.10.2)\n",
            "Collecting platformdirs>=2.2.0\n",
            "  Downloading platformdirs-2.4.1-py3-none-any.whl (14 kB)\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.2-py3-none-any.whl (235 kB)\n",
            "\u001b[K     |████████████████████████████████| 235 kB 68.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from python-cli-ui~=0.7.1->-r requirements.txt (line 14)) (0.8.9)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from python-cli-ui~=0.7.1->-r requirements.txt (line 14)) (0.4.4)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.4->Flask~=0.12->-r requirements.txt (line 6)) (2.0.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet>=1.2.0->gym~=0.10.5->-r requirements.txt (line 2)) (0.16.0)\n",
            "Building wheels for collected packages: gym, jsonmerge\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.10.11-py3-none-any.whl size=1588313 sha256=122d027704b570b8029b5b571a4e5d1b17f0bcb0b868e45861c371032d09ee9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/c9/3a/068c5b80305e89c8de8b0a412e67ef2986cbad74895cfb9551\n",
            "  Building wheel for jsonmerge (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonmerge: filename=jsonmerge-1.5.2-py3-none-any.whl size=15661 sha256=04b0dccef8391c24e8a1a0dcf767471ee558c9ba63f5b407f7ff0ce821959139\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/72/73/4fd3af3bc22616555b1ad8a374345543ed1b64e90b7d9cfe20\n",
            "Successfully built gym jsonmerge\n",
            "Installing collected packages: typed-ast, lazy-object-proxy, Werkzeug, websocket-client, unidecode, ruamel.yaml.clib, platformdirs, mccabe, isort, docker-pycreds, Click, astroid, websockets, ruamel.yaml, python-rapidjson, python-cli-ui, pylint, Pillow, jsonmerge, gym, Flask, docker\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "  Attempting uninstall: Click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: jsonmerge\n",
            "    Found existing installation: jsonmerge 1.8.0\n",
            "    Uninstalling jsonmerge-1.8.0:\n",
            "      Successfully uninstalled jsonmerge-1.8.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "  Attempting uninstall: Flask\n",
            "    Found existing installation: Flask 1.1.4\n",
            "    Uninstalling Flask-1.1.4:\n",
            "      Successfully uninstalled Flask-1.1.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bokeh 2.3.3 requires pillow>=7.1.0, but you have pillow 5.4.1 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Click-7.0 Flask-0.12.5 Pillow-5.4.1 Werkzeug-0.16.1 astroid-2.9.1 docker-3.7.3 docker-pycreds-0.4.0 gym-0.10.11 isort-4.3.21 jsonmerge-1.5.2 lazy-object-proxy-1.7.1 mccabe-0.6.1 platformdirs-2.4.1 pylint-2.12.2 python-cli-ui-0.7.5 python-rapidjson-0.6.3 ruamel.yaml-0.17.20 ruamel.yaml.clib-0.2.6 typed-ast-1.5.1 unidecode-1.3.2 websocket-client-0.53.0 websockets-6.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "gym",
                  "jsonmerge"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OeIGU3hgFOrL",
        "outputId": "2c6af73d-591e-4421-e605-2b39882c1e59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Import error NSDE! You will not be able to render --> Cannot connect to \"None\"\n"
          ]
        }
      ],
      "source": [
        "import colorama\n",
        "from pommerman import agents\n",
        "from collections import Counter\n",
        "import time\n",
        "import math\n",
        "import os\n",
        "import numpy.matlib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neuer Abschnitt"
      ],
      "metadata": {
        "id": "tSJfyfjoMpnT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pommerman\n",
        "from pommerman import agents\n",
        "import sys\n",
        "import gym\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "from collections import namedtuple\n",
        "from collections import Counter\n",
        "import multiprocessing as mp\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.distributions import Categorical\n",
        "\n",
        "# import matplotlib\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.ion()\n",
        "\n",
        "class Leif(agents.BaseAgent):\n",
        "    def __init__(self, model):\n",
        "        super(Leif, self).__init__()\n",
        "        self.model     = model\n",
        "        self.states    = []\n",
        "        self.actions   = []\n",
        "        self.hidden    = []\n",
        "        self.values    = []\n",
        "        self.probs     = []\n",
        "        self.debug     = False\n",
        "        self.stochastic = True\n",
        "        \n",
        "    def translate_obs(self, o):\n",
        "        obs_width = self.model.obs_width\n",
        "        \n",
        "        board = o['board'].copy()\n",
        "        agents = np.column_stack(np.where(board > 10))\n",
        "\n",
        "        for i, agent in enumerate(agents): \n",
        "            agent_id = board[agent[0], agent[1]]\n",
        "            if agent_id not in o['alive']: # < this fixes a bug >\n",
        "                board[agent[0], agent[1]] = 0\n",
        "            else:\n",
        "                board[agent[0], agent[1]] = 11\n",
        "\n",
        "        obs_radius = obs_width//2\n",
        "        pos = np.asarray(o['position'])\n",
        "\n",
        "        # board\n",
        "        board_pad = np.pad(board, (obs_radius,obs_radius), 'constant', constant_values=1)\n",
        "        self.board_cent = board_cent = board_pad[pos[0]:pos[0]+2*obs_radius+1,pos[1]:pos[1]+2*obs_radius+1]\n",
        "\n",
        "        # bomb blast strength\n",
        "        bbs = o['bomb_blast_strength']\n",
        "        bbs_pad = np.pad(bbs, (obs_radius,obs_radius), 'constant', constant_values=0)\n",
        "        self.bbs_cent = bbs_cent = bbs_pad[pos[0]:pos[0]+2*obs_radius+1,pos[1]:pos[1]+2*obs_radius+1]\n",
        "\n",
        "        # bomb life\n",
        "        bl = o['bomb_life']\n",
        "        bl_pad = np.pad(bl, (obs_radius,obs_radius), 'constant', constant_values=0)\n",
        "        self.bl_cent = bl_cent = bl_pad[pos[0]:pos[0]+2*obs_radius+1,pos[1]:pos[1]+2*obs_radius+1]\n",
        "\n",
        "        return np.concatenate((\n",
        "            board_cent, bbs_cent, bl_cent,\n",
        "            o['blast_strength'], o['can_kick'], o['ammo']), axis=None)\n",
        "\n",
        "    def act(self, obs, action_space):\n",
        "        obs = self.translate_obs(obs)\n",
        "        \n",
        "        last_hn, last_cn = self.hidden[-1][0], self.hidden[-1][1]\n",
        "        obs = torch.from_numpy(obs).float().to(self.model.device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            self.model.eval()\n",
        "            last_hn, last_cn = torch.tensor(last_hn).unsqueeze(0), torch.tensor(last_cn).unsqueeze(0)\n",
        "            probs, val, hn, cn = self.model(obs.unsqueeze(0), last_hn, last_cn, self.debug)\n",
        "            \n",
        "            if self.debug: \n",
        "                print(\"hn mean:\", hn.mean(), \"hn std:\", hn.std(), \"cn mean:\", cn.mean(), \"cn std:\", cn.std())\n",
        "            \n",
        "            probs_softmaxed = F.softmax(probs, dim=-1)\n",
        "\n",
        "            if self.stochastic:\n",
        "                action = Categorical(probs_softmaxed).sample().item()\n",
        "            else: \n",
        "                action = probs_softmaxed.max(1, keepdim=True)[1].item()\n",
        "\n",
        "        self.actions.append(action)\n",
        "        self.states.append(obs.squeeze(0).numpy())\n",
        "        self.probs.append(probs.detach().numpy())\n",
        "        self.values.append(val.detach().item())\n",
        "        self.hidden.append(\n",
        "            ( hn.squeeze(0).clone().detach().numpy(), \n",
        "              cn.squeeze(0).clone().detach().numpy() ))\n",
        "\n",
        "        return action\n",
        "    \n",
        "    def clear(self):\n",
        "        del self.states[:]\n",
        "        del self.actions[:]\n",
        "        del self.hidden[:]\n",
        "        del self.probs[:]\n",
        "        del self.values[:]\n",
        "\n",
        "        self.hidden.insert(0, self.model.init_rnn())\n",
        "\n",
        "        return self.states, self.actions, self.hidden, self.probs, self.values\n",
        "\n",
        "class Stoner(agents.BaseAgent):\n",
        "        def __init__(self): super(Stoner, self).__init__()\n",
        "        def act(self, obs, action_space): \n",
        "            return 0#random.randint(1,4) #0\n",
        "\n",
        "class A2CNet(nn.Module):\n",
        "    def __init__(self, gpu = True): \n",
        "        super(A2CNet, self).__init__()\n",
        "        \n",
        "        self.gamma             = 0.50   # Discount factor for rewards (default 0.99)\n",
        "        self.entropy_coef      = 0.01   # Entropy coefficient (0.01)\n",
        "        self.obs_width = w     = 17     # Window width/height (must be uneven)\n",
        "        self.lr                = 0.001  # 3e-2\n",
        "\n",
        "        self.inputs_to_conv = ic  = 3*(w**2)           # 3 boards\n",
        "        self.inputs_to_fc   = ifc = 3                  # blast strength, can_kick, ammo\n",
        "        self.conv_channels  = cc  = 45                 # number of conv outputs\n",
        "        #self.flat_after_c  = fac = cc * (w-3) * (w-3) # cc * (w-4) * (w-4) # flattened num after conv\n",
        "        #self.flat_after_c  = fac = cc * (w-2) * (w-2) # cc * (w-4) * (w-4) # flattened num after conv\n",
        "        #self.flat_after_c  = fac = cc * (w-cc) * (w-cc) # cc * (w-4) * (w-4) # flattened num after conv\n",
        "        self.flat_after_c  = fac = 13005\n",
        "\n",
        "        self.fc1s, self.fc2s, self.fc3s = 1024, 512, 64\n",
        "        \n",
        "        self.rnn_input_size   = self.fc2s \n",
        "        self.rnn_hidden_size  = 64\n",
        "        \n",
        "        self.conv1 = torch.nn.Conv2d(3,  cc,   kernel_size=3, stride=1, padding=1, groups=3)\n",
        "        self.conv2 = torch.nn.Conv2d(cc, cc,   kernel_size=3, stride=1, padding=1, groups=3) #dilation=2, stride=1, padding=1)\n",
        "        self.conv3 = torch.nn.Conv2d(cc, cc,   kernel_size=3, stride=1, padding=1, groups=3)\n",
        "        self.conv4 = torch.nn.Conv2d(cc, cc,   kernel_size=3, stride=1, padding=1, groups=3)\n",
        "\n",
        "        self.bn1, self.bn2 = nn.BatchNorm2d(cc), nn.BatchNorm2d(cc)\n",
        "        self.bn3, self.bn4 = nn.BatchNorm2d(cc), nn.BatchNorm2d(cc)\n",
        "\n",
        "        self.fc_after_conv1 = nn.Linear(fac, self.fc1s)\n",
        "        self.fc_after_conv2 = nn.Linear(self.fc1s + ifc, self.fc2s)\n",
        "        self.fc_after_conv3 = nn.Linear(self.fc2s, self.fc2s)\n",
        "        self.fc_after_conv4 = nn.Linear(self.fc2s, self.fc2s)\n",
        "        \n",
        "        self.rnn = torch.nn.LSTMCell(self.rnn_input_size, self.rnn_hidden_size)\n",
        "\n",
        "        self.fc_after_rnn_1 = nn.Linear(self.rnn_hidden_size, self.fc3s)\n",
        "        # self.fc_after_rnn_2 = nn.Linear(self.fc3s, self.fc3s)\n",
        "        # self.fc_after_rnn_3 = nn.Linear(self.fc3s, self.fc3s)\n",
        "        # self.fc_after_rnn_4 = nn.Linear(self.fc3s, self.fc3s)\n",
        "        \n",
        "        self.action_head = nn.Linear(self.fc3s, 6)\n",
        "        self.value_head  = nn.Linear(self.fc2s, 1)\n",
        "\n",
        "        self.optimizer   = optim.Adam(self.parameters(), lr=self.lr)\n",
        "        self.eps         = np.finfo(np.float32).eps.item()\n",
        "        \n",
        "        self.device = torch.device(\"cuda:0\" if gpu and torch.cuda.is_available() else \"cpu\")\n",
        "        if self.device.type == 'cuda': self.cuda()\n",
        "        return None\n",
        "\n",
        "    def forward(self, x, hn, cn, debug = False):\n",
        "        batch_size = x.shape[0]\n",
        "        w, wh = self.obs_width, self.obs_width**2\n",
        "        \n",
        "        boards  = x[:,      0:wh].view(batch_size, 1, w, w)\n",
        "        bbs     = x[:,   wh:wh*2].view(batch_size, 1, w, w)\n",
        "        bl      = x[:, wh*2:wh*3].view(batch_size, 1, w, w)\n",
        "        \n",
        "        rest    = x[:, wh*3:]\n",
        "        to_conv = torch.cat([boards, bbs, bl], 1)\n",
        "        \n",
        "        xc = self.conv1(to_conv)\n",
        "        xc = self.bn1(xc)\n",
        "        xc = F.relu(xc)\n",
        "\n",
        "        xc = self.conv2(xc)\n",
        "        xc = self.bn2(xc)\n",
        "        xc = F.relu(xc)\n",
        "\n",
        "        xc = self.conv3(xc)\n",
        "        xc = self.bn3(xc)\n",
        "        xc = F.relu(xc)\n",
        "\n",
        "        xc = self.conv4(xc)\n",
        "        xc = self.bn4(xc)\n",
        "        xc = F.relu(xc)\n",
        "        \n",
        "        xc = xc.view(batch_size, -1)\n",
        "        xc = self.fc_after_conv1(xc)\n",
        "        xc = F.relu(xc)\n",
        "        \n",
        "        xc = torch.cat((xc, rest), 1)\n",
        "        xc = self.fc_after_conv2(xc)\n",
        "        xc = F.relu(xc)\n",
        "\n",
        "        xc = self.fc_after_conv3(xc)\n",
        "        xc = F.relu(xc)\n",
        "        \n",
        "        xc = self.fc_after_conv4(xc)\n",
        "        xc = F.relu(xc)\n",
        "        \n",
        "        # if not debug:\n",
        "        #     print(xc[0, :].mean(), xc[0, :].std())\n",
        "\n",
        "        if debug == True:   \n",
        "            mm = xc[0, :].mean()\n",
        "            nn = xc[0, :].std()\n",
        "        \n",
        "        values  = self.value_head(xc)\n",
        "        hn, cn  = self.rnn(xc, (hn, cn))\n",
        "        xc = hn #torch.cat((xc, hn), 1)\n",
        "        \n",
        "        if debug == True:\n",
        "            mm1 = xc[0, :].mean()\n",
        "            nn1 = xc[0, :].std()\n",
        "            print(\"Before rnn:\", (mm,nn), \"After rnn:\", (mm1,nn1))\n",
        "        \n",
        "        xc = self.fc_after_rnn_1(xc)\n",
        "        xc = F.relu(xc)\n",
        "        \n",
        "        # xc = self.fc_after_rnn_2(xc)\n",
        "        # xc = F.relu(xc)\n",
        "\n",
        "        # xc = self.fc_after_rnn_3(xc)\n",
        "        # xc = F.relu(xc)\n",
        "        \n",
        "        # xc = self.fc_after_rnn_4(xc)\n",
        "        # xc = F.relu(xc)\n",
        "        \n",
        "        probs = self.action_head(xc)\n",
        "        \n",
        "        return probs, values, hn, cn\n",
        "        \n",
        "    def init_rnn(self):\n",
        "        device = self.device\n",
        "        s = self.rnn_hidden_size\n",
        "        return (torch.zeros(s).detach().numpy(), torch.zeros(s).detach().numpy())\n",
        "    \n",
        "    def discount_rewards(self, _rewards):\n",
        "        R = 0\n",
        "        gamma = self.gamma\n",
        "        rewards = []\n",
        "        for r in _rewards[::-1]:\n",
        "            R = r + gamma * R\n",
        "            rewards.insert(0, R)\n",
        "\n",
        "        # rewards = np.array(rewards) \n",
        "        # rewards = (rewards - rewards.mean()) / (rewards.std() + self.eps)\n",
        "        \n",
        "        return rewards #torch.from_numpy(rewards).to(self.device)\n",
        "\n",
        "def naked_env(agent_list):\n",
        "    env = gym.make('PommeRadioCompetition-v2')\n",
        "    env._num_items = 0\n",
        "    env._num_wood  = 0\n",
        "    env._num_rigid = 0\n",
        "    env._max_steps = 100\n",
        "\n",
        "    for id, agent in enumerate(agent_list):\n",
        "        assert isinstance(agent, agents.BaseAgent)\n",
        "        agent.init_agent(id, env.spec._kwargs['game_type'])\n",
        "\n",
        "    env.set_agents(agent_list)\n",
        "    env.set_init_game_state(None)\n",
        "    env.set_render_mode('human')\n",
        "    return env\n",
        "\n",
        "def normal_env(agent_list):\n",
        "    env = gym.make('PommeRadioCompetition-v2')\n",
        "    \n",
        "    for id, agent in enumerate(agent_list):\n",
        "        assert isinstance(agent, agents.BaseAgent)\n",
        "        agent.init_agent(id, env.spec._kwargs['game_type'])\n",
        "\n",
        "    env.set_agents(agent_list)\n",
        "    env.set_init_game_state(None)\n",
        "    env.set_render_mode('human')\n",
        "    return env"
      ],
      "metadata": {
        "id": "8Xlx6gIIBJEz"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "_blBAK9TFOrR",
        "outputId": "fa147b81-4c8a-4616-e2a3-75323ff4c1bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loaded checkpoint\n",
            "0 \t 0.501 -0.068 \twins: --- Counter({5: 16, 2: 5, 4: 5, 1: 3, 0: 2, 3: 1}) -6.915 -1.296 -1.696 0.399\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-3c27fe76e122>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;31m#evaluate(World())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWorld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-3c27fe76e122>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(world)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mii\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mfull_rollouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdo_rollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleif\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROLLOUTS_PER_BATCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munroll_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_rollouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mgmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.0003\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# adaptive gamma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-3c27fe76e122>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0mii\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mfull_rollouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdo_rollout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleif\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mROLLOUTS_PER_BATCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0mstates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munroll_rollouts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_rollouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0mgmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.0003\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m20000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# adaptive gamma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-3c27fe76e122>\u001b[0m in \u001b[0;36mdo_rollout\u001b[0;34m(env, leif, do_print)\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'board'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pommermanAI/reinforcement_learning/johannes/playground/playground/pommerman/envs/v0.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, obs)\u001b[0m\n\u001b[1;32m    135\u001b[0m         agents = [agent for agent in self._agents \\\n\u001b[1;32m    136\u001b[0m                   if agent.agent_id != self.training_agent]\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_observations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pommermanAI/reinforcement_learning/johannes/playground/playground/pommerman/forward_model.py\u001b[0m in \u001b[0;36mact\u001b[0;34m(agents, obs, action_space, is_communicative)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_with_communication\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m                 \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mact_ex_communication\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/pommermanAI/reinforcement_learning/johannes/playground/playground/pommerman/forward_model.py\u001b[0m in \u001b[0;36mact_ex_communication\u001b[0;34m(agent)\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;34m'''Handles agent's move without communication'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_space\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-e57df0065210>\u001b[0m in \u001b[0;36mact\u001b[0;34m(self, obs, action_space)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mlast_hn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_cn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_hn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_cn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_hn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_cn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-e57df0065210>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, hn, cn, debug)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mxc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mxc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_after_conv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0mxc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "ROLLOUTS_PER_BATCH = 1\n",
        "batch = []\n",
        "\n",
        "\n",
        "class World:\n",
        "    def __init__(self, init_gmodel=True):\n",
        "        if init_gmodel:\n",
        "            self.gmodel = A2CNet(gpu=True)  # Global model\n",
        "\n",
        "        self.model = A2CNet(gpu=False)  # Agent (local) model\n",
        "        self.leif = Leif(self.model)\n",
        "        self.stoner = Stoner()\n",
        "\n",
        "        self.agent_list = [\n",
        "            self.leif,\n",
        "            # self.stoner\n",
        "            agents.SimpleAgent(),\n",
        "            agents.SimpleAgent(),\n",
        "            agents.SimpleAgent()\n",
        "        ]\n",
        "        self.env = normal_env(self.agent_list)  # naked_env\n",
        "        fmt = {\n",
        "            'int': self.color_sign,\n",
        "            'float': self.color_sign\n",
        "        }\n",
        "        np.set_printoptions(formatter=fmt, linewidth=300)\n",
        "        pass\n",
        "\n",
        "    def color_sign(self, x):\n",
        "        if x == 0:\n",
        "            c = colorama.Fore.LIGHTBLACK_EX\n",
        "        elif x == 1:\n",
        "            c = colorama.Fore.BLACK\n",
        "        elif x == 2:\n",
        "            c = colorama.Fore.BLUE\n",
        "        elif x == 3:\n",
        "            c = colorama.Fore.RED\n",
        "        elif x == 4:\n",
        "            c = colorama.Fore.RED\n",
        "        elif x == 10:\n",
        "            c = colorama.Fore.YELLOW\n",
        "        else:\n",
        "            c = colorama.Fore.WHITE\n",
        "        x = '{0: <2}'.format(x)\n",
        "        return f'{c}{x}{colorama.Fore.RESET}'\n",
        "\n",
        "\n",
        "def do_rollout(env, leif, do_print=False):\n",
        "    done, state = False, env.reset()\n",
        "    rewards, dones = [], []\n",
        "    states, actions, hidden, probs, values = leif.clear()\n",
        "    old_state = None\n",
        "    last_action = 0\n",
        "\n",
        "    while not done and 10 in state[0]['alive']:\n",
        "        if do_print:\n",
        "            time.sleep(0.1)\n",
        "            os.system('clear')\n",
        "            print(state[0]['board'])\n",
        "\n",
        "        action = env.act(state)\n",
        "        state, start_rewards, done, info = env.step(action)\n",
        "        action = action[0]\n",
        "        if old_state is None:\n",
        "            old_state = state\n",
        "        reward = get_reward(state, old_state, 0, action, last_action)\n",
        "        # print(str(state[0]['position']) + str(old_state[0]['position']) + str(reward))\n",
        "        old_state = state\n",
        "        last_action = action\n",
        "        rewards.append(reward)\n",
        "        dones.append(done)\n",
        "\n",
        "    hidden = hidden[:-1].copy()\n",
        "    hns, cns = [], []\n",
        "    for hns_cns_tuple in hidden:\n",
        "        hns.append(hns_cns_tuple[0])\n",
        "        cns.append(hns_cns_tuple[1])\n",
        "\n",
        "    rewards = rewards[:len(values)]\n",
        "\n",
        "    return (states.copy(),\n",
        "            actions.copy(),\n",
        "            rewards, dones,\n",
        "            (hns, cns),\n",
        "            probs.copy(),\n",
        "            values.copy())\n",
        "\n",
        "\n",
        "def get_reward(state, old_state, agent_nr, action, last_action):\n",
        "    # developer note: on the board:\n",
        "    # 0: nothing, 1: unbreakable wall, 2: wall, 3: bomb, 4: flames, 6,7,8: pick-ups:  11,12 and 13: enemies\n",
        "    reward = 0\n",
        "    # penalty for dying\n",
        "    if 10 not in state[0]['alive']:\n",
        "        reward -= 1\n",
        "\n",
        "    # reward stage 0:\n",
        "    # teach the agent to move and not make invalid actions (move into walls, place bombs when you have no ammo)\n",
        "    ammo = old_state[agent_nr]['ammo']\n",
        "    if action != 5:\n",
        "        if state[agent_nr]['position'] == old_state[agent_nr]['position']:\n",
        "            reward -= 0.03\n",
        "    elif ammo == 0:\n",
        "        reward -= 0.03\n",
        "\n",
        "    # reward stage 1: teach agent to bomb walls (and enemies)\n",
        "    # compute adjacent squares\n",
        "    position = state[agent_nr]['position']\n",
        "    adj = [(i, j) for i in (-1, 0, 1) for j in (-1, 0, 1) if not ((i == j) or i + j == 0)]\n",
        "    adjacent = numpy.matlib.repmat(position, 4, 1)\n",
        "    adjacent = adjacent - np.asarray(adj)\n",
        "    # limit adjacent squares to only include inside board\n",
        "    adjacent = np.clip(adjacent, 0, 10)\n",
        "    if action == 5 and ammo > 0:\n",
        "        board = state[agent_nr]['board']\n",
        "        for xy in adjacent:\n",
        "            square_val = board[xy[0]][xy[1]]\n",
        "            if square_val == 2:\n",
        "                reward += 0.2\n",
        "            elif square_val == 11 or square_val == 12 or square_val == 13:\n",
        "                reward += 0.5\n",
        "\n",
        "    # reward stage2: teach agent to not stand on or beside bombs\n",
        "    # reward /= 4\n",
        "    bomb_life = state[agent_nr]['bomb_life']\n",
        "    # if we stand on a bomb or next to bomb\n",
        "    just_placed_bomb = np.logical_xor(last_action == 5, action == 5)\n",
        "    if bomb_life[position] > 0 and not just_placed_bomb:\n",
        "        reward -= 0.1 * (9-bomb_life[position])\n",
        "    for xy in adjacent:\n",
        "        if bomb_life[xy[0]][xy[1]] > 0:\n",
        "            reward -= 0.05 * (9-bomb_life[xy[0]][xy[1]])\n",
        "\n",
        "    # reward agent for picking up power-ups\n",
        "    blast_strength = state[agent_nr]['blast_strength']\n",
        "    old_blast_strength = old_state[agent_nr]['blast_strength']\n",
        "    can_kick = int(state[agent_nr]['can_kick'])\n",
        "    old_can_kick = int(old_state[agent_nr]['can_kick'])\n",
        "    reward += (can_kick-old_can_kick)*0.02\n",
        "    # reward += (max_ammo-old_max_ammo)*0.02 #TODO, see arguments\n",
        "    reward += (blast_strength-old_blast_strength)*0.02\n",
        "    return reward\n",
        "\n",
        "\n",
        "def gmodel_train(gmodel, states, hns, cns, actions, rewards, gae):\n",
        "    states, hns, cns = torch.stack(states), torch.stack(hns, dim=0), torch.stack(cns, dim=0)\n",
        "    gmodel.train()\n",
        "    probs, values, _, _ = gmodel(states.to(gmodel.device), hns.to(gmodel.device), cns.to(gmodel.device), debug=False)\n",
        "\n",
        "    prob = F.softmax(probs, dim=-1)\n",
        "    log_prob = F.log_softmax(probs, dim=-1)\n",
        "    entropy = -(log_prob * prob).sum(1)\n",
        "\n",
        "    log_probs = log_prob[range(0, len(actions)), actions]\n",
        "    advantages = torch.tensor(rewards).to(gmodel.device) - values.squeeze(1)\n",
        "    value_loss = advantages.pow(2) * 0.5\n",
        "    policy_loss = -log_probs * torch.tensor(gae).to(gmodel.device) - gmodel.entropy_coef * entropy\n",
        "\n",
        "    gmodel.optimizer.zero_grad()\n",
        "    pl = policy_loss.sum()\n",
        "    vl = value_loss.sum()\n",
        "    loss = pl + vl\n",
        "    loss.backward()\n",
        "    gmodel.optimizer.step()\n",
        "\n",
        "    return loss.item(), pl.item(), vl.item()\n",
        "\n",
        "\n",
        "def unroll_rollouts(gmodel, list_of_full_rollouts):\n",
        "    gamma = gmodel.gamma\n",
        "    tau = 1\n",
        "\n",
        "    states, actions, rewards, hns, cns, gae = [], [], [], [], [], []\n",
        "    for (s, a, r, d, h, p, v) in list_of_full_rollouts:\n",
        "        states.extend(torch.tensor(s))\n",
        "        actions.extend(a)\n",
        "        rewards.extend(gmodel.discount_rewards(r))\n",
        "\n",
        "        hns.extend([torch.tensor(hh) for hh in h[0]])\n",
        "        cns.extend([torch.tensor(hh) for hh in h[1]])\n",
        "\n",
        "        # Calculate GAE\n",
        "        last_i, _gae, __gae = len(r) - 1, [], 0\n",
        "        for i in reversed(range(len(r))):\n",
        "            next_val = v[i + 1] if i != last_i else 0\n",
        "            delta_t = r[i] + gamma * next_val - v[i]\n",
        "            __gae = __gae * gamma * tau + delta_t\n",
        "            _gae.insert(0, __gae)\n",
        "\n",
        "        gae.extend(_gae)\n",
        "\n",
        "    return states, hns, cns, actions, rewards, gae\n",
        "\n",
        "\n",
        "def train(world):\n",
        "    model, gmodel = world.model, world.gmodel\n",
        "    leif, env = world.leif, world.env\n",
        "\n",
        "    if os.path.isfile(\"convrnn-s.weights\"):  # turn off for new model\n",
        "        model.load_state_dict(torch.load(\"convrnn-s.weights\", map_location='cpu'))\n",
        "        gmodel.load_state_dict(torch.load(\"convrnn-s.weights\", map_location='cpu'))\n",
        "        print(\"loaded checkpoint\")\n",
        "\n",
        "    if os.path.exists(\"training.txt\"):\n",
        "        os.remove(\"training.txt\")\n",
        "\n",
        "    rr = 0\n",
        "    ii = 0\n",
        "    for i in range(30001):\n",
        "        full_rollouts = [do_rollout(env, leif) for _ in range(ROLLOUTS_PER_BATCH)]\n",
        "        states, hns, cns, actions, rewards, gae = unroll_rollouts(gmodel, full_rollouts)\n",
        "        gmodel.gamma = 0.5 + 1 / 2. / (1 + math.exp(-0.0003 * (i - 20000)))  # adaptive gamma\n",
        "        l, pl, vl = gmodel_train(gmodel, states, hns, cns, actions, rewards, gae)\n",
        "        rr = rr * 0.99 + (np.mean(rewards) / len(actions)) / ROLLOUTS_PER_BATCH * 0.01\n",
        "        ii += len(actions)\n",
        "        print(i, \"\\t\", round(gmodel.gamma, 3), round(rr*1000, 3), \"\\twins:\", \"---\", Counter(actions),\n",
        "              round(sum(rewards), 3), round(l, 3), round(pl, 3), round(vl, 3))\n",
        "        with open(\"training.txt\", \"a\") as f:\n",
        "            print(rr, \"\\t\", round(gmodel.gamma, 4), \"\\t\", round(vl, 3), \"\\t\", round(pl, 3), \"\\t\", round(l, 3), file=f)\n",
        "        model.load_state_dict(gmodel.state_dict())\n",
        "        if i >= 10 and i % 30 == 0:\n",
        "            torch.save(gmodel.state_dict(), \"convrnn-s.weights\")\n",
        "            print(\"saved weights\")\n",
        "\n",
        "\n",
        "def run(world):\n",
        "    done, ded, state, _ = False, False, world.env.reset(), world.leif.clear()\n",
        "\n",
        "    while not done:\n",
        "        action = world.env.act(state)\n",
        "        state, reward, done, info = world.env.step(action)\n",
        "        print(world.leif.board_cent)\n",
        "        print(world.leif.bbs_cent)\n",
        "        print(world.leif.bl_cent)\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    world.env.close()\n",
        "    return None\n",
        "\n",
        "\n",
        "def evaluate(world):\n",
        "    env = world.env\n",
        "    model = world.model\n",
        "    leif = world.leif\n",
        "    leif.debug = True\n",
        "    leif.stochastic = True\n",
        "\n",
        "    do_print = True\n",
        "    reward = 0\n",
        "\n",
        "    while True:\n",
        "        model.load_state_dict(torch.load(\"convrnn-s.weights\", map_location='cpu'))\n",
        "\n",
        "        done, state, _ = False, env.reset(), leif.clear()\n",
        "        t = 0\n",
        "        while not done:\n",
        "            env.render()\n",
        "            if do_print:\n",
        "                time.sleep(0.1)\n",
        "                # os.system('clear')\n",
        "                print(state[0]['board'])\n",
        "                print(\"\\n\\n\")\n",
        "                print(\"Probs: \\t\", leif.probs[-1] if len(leif.probs) > 0 else [])\n",
        "                print(\"Val: \\t\", leif.values[-1] if len(leif.values) > 0 else None)\n",
        "                print(\"\\nReward: \", reward, \"Time\", t)\n",
        "\n",
        "            action = env.act(state)\n",
        "            state, reward, done, info = env.step(action)\n",
        "            t += 1\n",
        "\n",
        "\n",
        "#evaluate(World())\n",
        "train(World())\n",
        "# alpha, fließender durchschnitsswert für rewards | winrate | 5 bombe 0 stehen | "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add .\n",
        "!git commit -m \"newest changes jg\"\n",
        "!git push"
      ],
      "metadata": {
        "id": "poZ7rSNpFl9w",
        "outputId": "71b8b622-100f-4a39-8cbf-3d52c171e88c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch master\n",
            "Your branch is ahead of 'origin/master' by 1 commit.\n",
            "  (use \"git push\" to publish your local commits)\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}